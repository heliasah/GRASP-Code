{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO6RT8OS4mWs",
        "outputId": "6119feab-0694-4554-da2e-6c93a83011c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['S040.csv',\n",
              " 'S008.csv',\n",
              " 'S084.csv',\n",
              " 'S043.csv',\n",
              " 'S051.csv',\n",
              " 'S005.csv',\n",
              " 'S038.csv',\n",
              " 'S014.csv',\n",
              " 'S045.csv',\n",
              " 'S019.csv',\n",
              " 'S086.csv',\n",
              " 'S047.csv',\n",
              " 'S072.csv',\n",
              " 'S007.csv',\n",
              " 'S017.csv',\n",
              " 'S048.csv',\n",
              " 'S011.csv',\n",
              " 'S076.csv',\n",
              " 'S034.csv',\n",
              " 'S078.csv',\n",
              " 'S041.csv',\n",
              " 'S058.csv',\n",
              " 'S036.csv',\n",
              " 'S059.csv',\n",
              " 'S023.csv',\n",
              " 'S063.csv',\n",
              " 'S026.csv',\n",
              " 'S085.csv',\n",
              " 'S062.csv',\n",
              " 'S067.csv',\n",
              " 'S009.csv',\n",
              " 'S025.csv',\n",
              " 'S088.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the uploaded zip file\n",
        "uploaded_zip = 'males_train_matrices.zip'  # Update with your zip file path\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/unzipped_files/')\n",
        "\n",
        "# Get the folder name from the zip file (same name as the zip)\n",
        "folder_name = uploaded_zip.split('.')[0]  # Remove the '.zip' extension\n",
        "folder_path = os.path.join('/content/unzipped_files/', folder_name)\n",
        "\n",
        "# List the files inside the folder\n",
        "os.listdir(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a folder for saving npy files\n",
        "npy_folder = '/content/npy_files/'\n",
        "os.makedirs(npy_folder, exist_ok=True)\n",
        "\n",
        "# List the CSV files in the extracted folder\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Loop through each CSV file, convert it to npy, and save it\n",
        "for csv_file in csv_files:\n",
        "    csv_path = os.path.join(folder_path, csv_file)\n",
        "\n",
        "    # Read CSV as numpy array\n",
        "    matrix = np.loadtxt(csv_path, delimiter=',')  # Adjust delimiter if needed\n",
        "\n",
        "    # Save as .npy file\n",
        "    npy_file = os.path.join(npy_folder, csv_file.replace('.csv', '.npy'))\n",
        "    np.save(npy_file, matrix)\n",
        "\n",
        "print(f\"Converted {len(csv_files)} CSV files to NPY.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMtVfBQQJ9us",
        "outputId": "dc2c59f6-985b-4f83-e6c9-84bbcd8ba44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 33 CSV files to NPY.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create a zip file containing the npy files\n",
        "shutil.make_archive('/content/npy_files_archive', 'zip', npy_folder)\n",
        "\n",
        "# List the files to verify\n",
        "os.listdir(npy_folder)\n",
        "from google.colab import files\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content/npy_files_archive.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a3pDIbqVKAM9",
        "outputId": "202d8313-ade5-497d-ea87-2810522ace1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_57af4d60-9ce7-4251-8fd4-85d9482ac30f\", \"npy_files_archive.zip\", 1389609)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the uploaded zip file\n",
        "uploaded_zip = 'females_train_matrices.zip'  # Update with your zip file path\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/unzipped_files/')\n",
        "\n",
        "# Get the folder name from the zip file (same name as the zip)\n",
        "folder_name = uploaded_zip.split('.')[0]  # Remove the '.zip' extension\n",
        "folder_path = os.path.join('/content/unzipped_files/', folder_name)\n",
        "\n",
        "# List the files inside the folder\n",
        "os.listdir(folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J2aJkZ7KwZJ",
        "outputId": "ab40be30-8c29-4601-b0cb-d5529424c1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['S001.csv',\n",
              " 'S006.csv',\n",
              " 'S069.csv',\n",
              " 'S031.csv',\n",
              " 'S021.csv',\n",
              " 'S020.csv',\n",
              " 'S055.csv',\n",
              " 'S082.csv',\n",
              " 'S056.csv',\n",
              " 'S035.csv',\n",
              " 'S068.csv',\n",
              " 'S046.csv',\n",
              " 'S066.csv',\n",
              " 'S057.csv',\n",
              " 'S003.csv',\n",
              " 'S087.csv',\n",
              " 'S070.csv',\n",
              " 'S028.csv',\n",
              " 'S015.csv',\n",
              " 'S054.csv',\n",
              " 'S071.csv',\n",
              " 'S079.csv',\n",
              " 'S037.csv',\n",
              " 'S073.csv',\n",
              " 'S083.csv',\n",
              " 'S060.csv',\n",
              " 'S075.csv',\n",
              " 'S024.csv',\n",
              " 'S074.csv',\n",
              " 'S002.csv',\n",
              " 'S029.csv',\n",
              " 'S032.csv',\n",
              " 'S016.csv',\n",
              " 'S065.csv',\n",
              " 'S050.csv',\n",
              " 'S027.csv',\n",
              " 'S013.csv',\n",
              " 'S052.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a folder for saving npy files\n",
        "npy_folder = '/content/female/'\n",
        "os.makedirs(npy_folder, exist_ok=True)\n",
        "\n",
        "# List the CSV files in the extracted folder\n",
        "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Loop through each CSV file, convert it to npy, and save it\n",
        "for csv_file in csv_files:\n",
        "    csv_path = os.path.join(folder_path, csv_file)\n",
        "\n",
        "    # Read CSV as numpy array\n",
        "    matrix = np.loadtxt(csv_path, delimiter=',')  # Adjust delimiter if needed\n",
        "\n",
        "    # Save as .npy file\n",
        "    npy_file = os.path.join(npy_folder, csv_file.replace('.csv', '.npy'))\n",
        "    np.save(npy_file, matrix)\n",
        "\n",
        "print(f\"Converted {len(csv_files)} CSV files to NPY.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--cYlJkXK2Y4",
        "outputId": "393230db-9cf8-4cdd-ef52-65653970ef74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 38 CSV files to NPY.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Create a zip file containing the npy files\n",
        "shutil.make_archive('/content/npy_files_females', 'zip', npy_folder)\n",
        "\n",
        "# List the files to verify\n",
        "os.listdir(npy_folder)\n",
        "from google.colab import files\n",
        "\n",
        "# # Download the zip file\n",
        "# files.download('/content/npy_files_females.zip')\n"
      ],
      "metadata": {
        "id": "kyRkFvZrK4pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to the zip files\n",
        "male_zip_path = 'npy_files_archive.zip'\n",
        "female_zip_path = 'npy_files_females.zip'\n",
        "\n",
        "# Define extraction paths\n",
        "male_extract_path = 'male_train_matrices'\n",
        "female_extract_path = 'female_train_matrices'\n",
        "\n",
        "# Extract the zip files\n",
        "with zipfile.ZipFile(male_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(male_extract_path)\n",
        "\n",
        "with zipfile.ZipFile(female_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(female_extract_path)\n",
        "\n",
        "# Now, the NPY files are directly in the extraction folders\n",
        "male_train_matrices = []\n",
        "female_train_matrices = []\n",
        "\n",
        "# Load all NPY files for males directly from the extraction folder\n",
        "for filename in os.listdir(male_extract_path):\n",
        "    if filename.endswith('.npy'):\n",
        "        file_path = os.path.join(male_extract_path, filename)\n",
        "        male_matrix = np.load(file_path)\n",
        "        male_train_matrices.append(male_matrix)\n",
        "\n",
        "# Load all NPY files for females directly from the extraction folder\n",
        "for filename in os.listdir(female_extract_path):\n",
        "    if filename.endswith('.npy'):\n",
        "        file_path = os.path.join(female_extract_path, filename)\n",
        "        female_matrix = np.load(file_path)\n",
        "        female_train_matrices.append(female_matrix)\n",
        "\n",
        "# Check if matrices are loaded correctly\n",
        "print(\"Number of male matrices:\", len(male_train_matrices))\n",
        "print(\"Number of female matrices:\", len(female_train_matrices))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPjubTCwLbgb",
        "outputId": "92ad12c3-d158-424e-ff5a-b665129812e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of male matrices: 33\n",
            "Number of female matrices: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import random\n",
        "\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "import random\n",
        "\n",
        "\n",
        "# Convert a matrix to edge list and edge weights\n",
        "def matrix_to_graph(matrix):\n",
        "    # Use from_numpy_array instead of from_numpy_matrix\n",
        "    G = nx.from_numpy_array(matrix, create_using=nx.DiGraph)  # Directed graph\n",
        "    edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
        "    edge_weights = torch.tensor([G[u][v]['weight'] for u, v in G.edges], dtype=torch.float32)\n",
        "    return edge_index, edge_weights\n",
        "\n",
        "\n",
        "# Create the graph data for males and females\n",
        "male_train_graphs = []\n",
        "female_train_graphs = []\n",
        "\n",
        "# Process male matrices\n",
        "for matrix in male_train_matrices:\n",
        "    edge_index, edge_weights = matrix_to_graph(matrix)\n",
        "    # Node features are the row vectors of the matrix (connections to all other nodes)\n",
        "    node_features = torch.tensor(matrix, dtype=torch.float32)  # Directly use the connectivity matrix as features\n",
        "    # Append data object\n",
        "    male_train_graphs.append(Data(x=node_features, edge_index=edge_index, edge_attr=edge_weights, y=torch.tensor([0])))  # 0 for male\n",
        "\n",
        "# Process female matrices\n",
        "for matrix in female_train_matrices:\n",
        "    edge_index, edge_weights = matrix_to_graph(matrix)\n",
        "    node_features = torch.tensor(matrix, dtype=torch.float32)  # Directly use the connectivity matrix as features\n",
        "    female_train_graphs.append(Data(x=node_features, edge_index=edge_index, edge_attr=edge_weights, y=torch.tensor([1])))  # 1 for female\n",
        "\n",
        "\n",
        "torch.manual_seed(12345)\n",
        "\n",
        "# Combine both male and female data\n",
        "graphs_train = male_train_graphs + female_train_graphs\n",
        "random.shuffle(graphs_train)\n",
        "\n",
        "print(len(graphs_train))\n",
        "print(graphs_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RXBWwY4Lr23",
        "outputId": "a3d0a09c-7a54-466b-e7ca-f314ffb3401b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "71\n",
            "[Data(x=[90, 90], edge_index=[2, 5857], edge_attr=[5857], y=[1]), Data(x=[90, 90], edge_index=[2, 6795], edge_attr=[6795], y=[1]), Data(x=[90, 90], edge_index=[2, 6470], edge_attr=[6470], y=[1]), Data(x=[90, 90], edge_index=[2, 6033], edge_attr=[6033], y=[1]), Data(x=[90, 90], edge_index=[2, 5866], edge_attr=[5866], y=[1]), Data(x=[90, 90], edge_index=[2, 6447], edge_attr=[6447], y=[1]), Data(x=[90, 90], edge_index=[2, 6515], edge_attr=[6515], y=[1]), Data(x=[90, 90], edge_index=[2, 6039], edge_attr=[6039], y=[1]), Data(x=[90, 90], edge_index=[2, 5875], edge_attr=[5875], y=[1]), Data(x=[90, 90], edge_index=[2, 6690], edge_attr=[6690], y=[1]), Data(x=[90, 90], edge_index=[2, 6149], edge_attr=[6149], y=[1]), Data(x=[90, 90], edge_index=[2, 6357], edge_attr=[6357], y=[1]), Data(x=[90, 90], edge_index=[2, 6614], edge_attr=[6614], y=[1]), Data(x=[90, 90], edge_index=[2, 6331], edge_attr=[6331], y=[1]), Data(x=[90, 90], edge_index=[2, 6519], edge_attr=[6519], y=[1]), Data(x=[90, 90], edge_index=[2, 6221], edge_attr=[6221], y=[1]), Data(x=[90, 90], edge_index=[2, 6488], edge_attr=[6488], y=[1]), Data(x=[90, 90], edge_index=[2, 6435], edge_attr=[6435], y=[1]), Data(x=[90, 90], edge_index=[2, 6430], edge_attr=[6430], y=[1]), Data(x=[90, 90], edge_index=[2, 6369], edge_attr=[6369], y=[1]), Data(x=[90, 90], edge_index=[2, 6627], edge_attr=[6627], y=[1]), Data(x=[90, 90], edge_index=[2, 6451], edge_attr=[6451], y=[1]), Data(x=[90, 90], edge_index=[2, 6414], edge_attr=[6414], y=[1]), Data(x=[90, 90], edge_index=[2, 5562], edge_attr=[5562], y=[1]), Data(x=[90, 90], edge_index=[2, 6377], edge_attr=[6377], y=[1]), Data(x=[90, 90], edge_index=[2, 6674], edge_attr=[6674], y=[1]), Data(x=[90, 90], edge_index=[2, 5618], edge_attr=[5618], y=[1]), Data(x=[90, 90], edge_index=[2, 6320], edge_attr=[6320], y=[1]), Data(x=[90, 90], edge_index=[2, 6696], edge_attr=[6696], y=[1]), Data(x=[90, 90], edge_index=[2, 6026], edge_attr=[6026], y=[1]), Data(x=[90, 90], edge_index=[2, 6507], edge_attr=[6507], y=[1]), Data(x=[90, 90], edge_index=[2, 5650], edge_attr=[5650], y=[1]), Data(x=[90, 90], edge_index=[2, 6536], edge_attr=[6536], y=[1]), Data(x=[90, 90], edge_index=[2, 7388], edge_attr=[7388], y=[1]), Data(x=[90, 90], edge_index=[2, 5940], edge_attr=[5940], y=[1]), Data(x=[90, 90], edge_index=[2, 6031], edge_attr=[6031], y=[1]), Data(x=[90, 90], edge_index=[2, 6239], edge_attr=[6239], y=[1]), Data(x=[90, 90], edge_index=[2, 6460], edge_attr=[6460], y=[1]), Data(x=[90, 90], edge_index=[2, 6791], edge_attr=[6791], y=[1]), Data(x=[90, 90], edge_index=[2, 6518], edge_attr=[6518], y=[1]), Data(x=[90, 90], edge_index=[2, 6798], edge_attr=[6798], y=[1]), Data(x=[90, 90], edge_index=[2, 7196], edge_attr=[7196], y=[1]), Data(x=[90, 90], edge_index=[2, 6945], edge_attr=[6945], y=[1]), Data(x=[90, 90], edge_index=[2, 5276], edge_attr=[5276], y=[1]), Data(x=[90, 90], edge_index=[2, 6100], edge_attr=[6100], y=[1]), Data(x=[90, 90], edge_index=[2, 5121], edge_attr=[5121], y=[1]), Data(x=[90, 90], edge_index=[2, 5773], edge_attr=[5773], y=[1]), Data(x=[90, 90], edge_index=[2, 6646], edge_attr=[6646], y=[1]), Data(x=[90, 90], edge_index=[2, 6214], edge_attr=[6214], y=[1]), Data(x=[90, 90], edge_index=[2, 6028], edge_attr=[6028], y=[1]), Data(x=[90, 90], edge_index=[2, 6425], edge_attr=[6425], y=[1]), Data(x=[90, 90], edge_index=[2, 6179], edge_attr=[6179], y=[1]), Data(x=[90, 90], edge_index=[2, 5827], edge_attr=[5827], y=[1]), Data(x=[90, 90], edge_index=[2, 5908], edge_attr=[5908], y=[1]), Data(x=[90, 90], edge_index=[2, 5974], edge_attr=[5974], y=[1]), Data(x=[90, 90], edge_index=[2, 6708], edge_attr=[6708], y=[1]), Data(x=[90, 90], edge_index=[2, 5991], edge_attr=[5991], y=[1]), Data(x=[90, 90], edge_index=[2, 6787], edge_attr=[6787], y=[1]), Data(x=[90, 90], edge_index=[2, 6197], edge_attr=[6197], y=[1]), Data(x=[90, 90], edge_index=[2, 6961], edge_attr=[6961], y=[1]), Data(x=[90, 90], edge_index=[2, 6487], edge_attr=[6487], y=[1]), Data(x=[90, 90], edge_index=[2, 6215], edge_attr=[6215], y=[1]), Data(x=[90, 90], edge_index=[2, 6087], edge_attr=[6087], y=[1]), Data(x=[90, 90], edge_index=[2, 4857], edge_attr=[4857], y=[1]), Data(x=[90, 90], edge_index=[2, 6385], edge_attr=[6385], y=[1]), Data(x=[90, 90], edge_index=[2, 6479], edge_attr=[6479], y=[1]), Data(x=[90, 90], edge_index=[2, 6664], edge_attr=[6664], y=[1]), Data(x=[90, 90], edge_index=[2, 6097], edge_attr=[6097], y=[1]), Data(x=[90, 90], edge_index=[2, 6701], edge_attr=[6701], y=[1]), Data(x=[90, 90], edge_index=[2, 6288], edge_attr=[6288], y=[1]), Data(x=[90, 90], edge_index=[2, 6851], edge_attr=[6851], y=[1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(graphs_train, '/content/graphs_train.pt')\n",
        "\n",
        "print(\"Graphs saved to '/content/graphs_train.pt'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqSrKFxlMAZR",
        "outputId": "fdb278fd-1493-4233-ba00-96361315989a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graphs saved to '/content/graphs_train.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the saved .pt file\n",
        "shutil.make_archive('/content/graphs_train_archive', 'zip', '/content', 'graphs_train.pt')\n",
        "\n",
        "# Verify the zip file has been created\n",
        "os.listdir('/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKoMWLolMD1r",
        "outputId": "a7746986-72f7-422d-ee97-35401ae7d881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'male_train_matrices',\n",
              " 'females_train_matrices.zip',\n",
              " 'males_train_matrices.zip',\n",
              " 'npy_files_archive.zip',\n",
              " 'npy_files_females.zip',\n",
              " 'unzipped_files',\n",
              " 'npy_files',\n",
              " 'graphs_train.pt',\n",
              " 'female',\n",
              " 'female_train_matrices',\n",
              " 'graphs_train_archive.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Provide the download link for the zip file\n",
        "# files.download('/content/graphs_train_archive.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GYhS6o_dMHEe",
        "outputId": "3d5ad6d4-ff49-4b0e-d036-1231e0c3119b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0db5833a-d0be-40eb-8a6c-ae43e22a42d3\", \"graphs_train_archive.zip\", 3369943)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_graphs = torch.load('graphs_train.pt')\n",
        "print(len(train_graphs))\n",
        "test_graphs = torch.load('graphs_test.pt')\n",
        "print(len(test_graphs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_1qe4j3Rew3",
        "outputId": "e5e68c66-867b-4bc2-9b84-905541e65d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n",
            "17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c3a6001159e4>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_graphs = torch.load('graphs_train.pt')\n",
            "<ipython-input-13-c3a6001159e4>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_graphs = torch.load('graphs_test.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, out_channels)\n",
        "        self.dropout = nn.Dropout(p=0.7)  # Added dropout layer\n",
        "        self.fc = torch.nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)  # Apply dropout after activation\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "        x = self.fc(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 90 # Each matrix is 90x90, so in_channels=90\n",
        "hidden_channels = 64  # You can adjust this based on the complexity of your dataset\n",
        "out_channels = 64  # Typically, this would be a smaller value (e.g., 32 or 64)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model = GCN(in_channels=in_channels, out_channels=out_channels)\n",
        "# Define loss function (binary cross-entropy for classification)\n",
        "loss_fn = nn.BCELoss()\n",
        "# Define optimizer (Adam)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Add weight_decay\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "metadata": {
        "id": "iJ-xpKg3RT_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_graphs, batch_size=16, shuffle=False)\n",
        "\n",
        "# Remove the initial incorrect training loop and use only this:\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:  # Correct training data\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch)\n",
        "        loss = loss_fn(output.view(-1), batch.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "Fc6GXLsRRxaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, loader):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed for evaluation\n",
        "        for batch in loader:\n",
        "            output = model(batch)  # Forward pass\n",
        "            predictions = (output.view(-1) > 0.5).long()  # Convert probabilities to binary labels\n",
        "            correct += (predictions == batch.y).sum().item()\n",
        "            total += batch.y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "test_accuracy = compute_accuracy(model, test_loader)\n",
        "\n",
        "print(f'Test Accuracy for GCN: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceJ-AoRXR0uZ",
        "outputId": "3d1910a4-864d-4336-9f8f-4bcf381c94d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for GCN: 0.5882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, heads=8):\n",
        "        super(GAT, self).__init__()\n",
        "        # First GAT layer\n",
        "        self.gat1 = GATConv(in_channels, 64, heads=heads, concat=True)  # Multiple attention heads\n",
        "        # Second GAT layer\n",
        "        self.gat2 = GATConv(64 * heads, out_channels, heads=1, concat=False)  # Output layer\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout for regularization\n",
        "        self.fc = torch.nn.Linear(out_channels, 1)  # Fully connected layer for the output\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # First GAT layer with Batch Normalization and ReLU\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.relu(x)  # ReLU activation\n",
        "        x = self.dropout(x)  # Dropout\n",
        "\n",
        "        # Second GAT layer with Batch Normalization and ReLU\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = F.relu(x)  # ReLU activation\n",
        "        x = self.dropout(x)  # Dropout\n",
        "\n",
        "        # Global pooling and output\n",
        "        x = global_mean_pool(x, data.batch)  # Global pooling for the graph\n",
        "        x = self.fc(x)  # Final output layer\n",
        "        x = torch.sigmoid(x)  # Sigmoid for binary classification\n",
        "\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = male_train_matrices[0].shape[0]  # Each matrix is 90x90, so in_channels=90\n",
        "hidden_channels = 64  # You can adjust this based on the complexity of your dataset\n",
        "out_channels = 64  # Typically, this would be a smaller value (e.g., 32 or 64)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50\n",
        "heads = 8  # Number of attention heads in the first GAT layer\n",
        "\n",
        "# Create the model\n",
        "model2 = GAT(in_channels=in_channels, out_channels=out_channels, heads=heads)\n",
        "\n",
        "# Define loss function (binary cross-entropy for classification)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# Define optimizer (Adam)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ip_z0VHXl0wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_graphs, batch_size=16, shuffle=False)\n",
        "\n",
        "# Remove the initial incorrect training loop and use only this:\n",
        "for epoch in range(num_epochs):\n",
        "    model2.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:  # Correct training data\n",
        "        optimizer.zero_grad()\n",
        "        output = model2(batch)\n",
        "        loss = loss_fn(output.view(-1), batch.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n"
      ],
      "metadata": {
        "id": "glxyRVzAl4Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, loader):\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed for evaluation\n",
        "        for batch in loader:\n",
        "            output = model(batch)  # Forward pass\n",
        "            predictions = (output.view(-1) > 0.5).long()  # Convert probabilities to binary labels\n",
        "            correct += (predictions == batch.y).sum().item()\n",
        "            total += batch.y.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "test_accuracy = compute_accuracy(model2, test_loader)\n",
        "\n",
        "print(f'Test Accuracy for GAT: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrMtcyaql7uj",
        "outputId": "b0939d00-5431-4fcb-a67f-67d7d0d0f583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for GAT: 0.5882\n"
          ]
        }
      ]
    }
  ]
}